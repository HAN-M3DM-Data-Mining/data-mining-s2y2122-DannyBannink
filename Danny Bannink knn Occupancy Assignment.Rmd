---
title: "Assigment - kNN DIY"
author:
  - Danny Bannink - Author
  - Teun Vlassak - Reviewer
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
   html_notebook:
    toc: true
    toc_depth: 2
---

```{r}
library(tidyverse)
library(googlesheets4)
library(class)
library(caret)
```

------------------------------------------------------------------------

### Setup library

```{r}
install.packages("caTools")
install.packages("XML")
install.packages("rvest")
install.packages("GGally")
library(tidyverse)
library(caTools)
library(XML)
library(rvest)
library(GGally)
```

# Business Understanding

### An article about the office occupancy concerning the used data in this script has been published. The article can be found at "<https://www.researchgate.net/profile/Luis_Candanedo_Ibarra/publication/285627413_Accurate_occupancy_detection_of_an_office_room_from_light_temperature_humidity_and_CO2_measurements_using_statistical_learning_models/links/5b1d843ea6fdcca67b690c28/Accurate-occupancy-detection-of-an-office-room-from-light-temperature-humidity-and-CO2-measurements-using-statistical-learning-models.pdf>". In this article a situation has been described in which they try to predict the occupancy of an office-room on the basis of several variables, which are: Temperature, Humidity, Light, CO2 and HumidityRatio.

### The goal of the article seems to be that energy usage is to be reduced concerning the occupation of the office-rooms.

# Data Understanding

### In order to understand the data, we first need to take a look at the data.

```{r}
rdf <- KNN_occupancy
head(KNN_occupancy)
```

### Based on the datatable we can conclude that there or 8143 obs. (rows) of 7 variables. (columns).

```{r}
str(KNN_occupancy)
```

# Data Preparation

### Since the date within the data set has no value on doing analysis, the choice is to delete this column.

```{r}
cdf <- rdf[-1]
head(cdf)
```

### The article which was talked about before, speaks of determining the occupancy of the office-rooms. The current estimation of the office occupancy detection has been made in order to save energy usage. Because of this, it is assumed that the outcome of the label 'Occupancy' should be predicted. Therefore the variable 'Occupancy' has to be labeled by making the datatype a 'factor'.

```{r}
cntDiag <- table(cdf$Occupancy) # This is the variable we want the outcomes of the tests from
propDiag <- round(prop.table(cntDiag) * 100 , digits = 1) # Making the table which shows the outcomes

cntDiag # 0 = Unoccupied, 1 = Occupied
```

```{r}
propDiag # Here we see the percentages of the occupancies of the office-rooms
```

```{r}
cdf$Occupancy <- as.numeric(cdf$Occupancy)
```

```{r}
cdf$Occupancy <- factor(cdf$Occupancy, levels = c("0", "1"), labels = c("Unoccupied", "Occupied")) %>% relevel("Occupied")
head(cdf, 10) # The variable 'Occupancy' has now been labeled and has gotten the datatype factor
```

### Of the 5 leftover variables, 4 are measurements. In order to be able to model these, we need to take a closer look at the statistical values of these variables.

```{r}
summary(cdf[c("Temperature", "Humidity", "Light", "CO2")])
```

### To be able to get all 4 variables in 1 model to calculate the distance, the data needs to be 'normalized'. This means that the differences of the values will be brought closer together so the scaling of the values complements eachother better for the model. The model which is talked about, is the K-Nearest Neighbor algorithm.

### First the normalization function has to be written

```{r}
normalize <- function(x) { # Function takes in a vector
  return ((x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))) # distance of item value - minimum vector value divided by the range of all vector values
}

testSet1 <- c(1:5)
testSet2 <- c(1:5) * 10

cat("testSet1:", testSet1, "\n") # First testSet1 is deployed to see if it works accordingly
```

```{r}
cat("testSet2:", testSet2, "\n") # The same with testSet2
```

```{r}
cat("Normalized testSet1:", normalize(testSet1), "\n") # Here the function will be tested on testSet1
```

```{r}
cat("Normalized testSet2:", normalize(testSet2)) # Here the function is tested on testSet2
```

### Now the new normalization function will be applied to the dataset of 4 variables

```{r}
normcdf <- as.data.frame(apply(cdf[1:4],2,normalize))
```

```{r}
summary(normcdf[c("Temperature", "Humidity", "Light", "CO2")])
```

### The last preperation that has to be done before the modelling phase can start, is splitting the data in a testset and a trainingset.

```{r}
sample_n(normcdf, (.8*8143)) # Inspecting the data
```

```{r}
# Splitting data (from normcdf, so labels aren't included) intro training and testing data
train.data <- normcdf[1:6514,]
test.data <- normcdf[6515:8143,]
```

```{r}
# Splitting data (from cdf, so only labels are included) intro training and testing data
train.label <- cdf[1:6514,]
test.label <- cdf[6515:8143,]
```

# Modeling

```{r}
cleanDF_test_pred <- knn(train = as.matrix(train.data), test = as.matrix(test.data), cl = as.matrix(train.label), k = 21)
head(cleanDF_test_pred)
```

```{r}
cleanDF_test_pred <- knn(train = train.data,
                                test = test.data,
                                cl = train.label, k = 21)
head(cleanDF_test_pred)
```

# Evaluation and Deployment

text and code here

reviewer adds suggestions for improving the model
